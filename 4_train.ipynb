{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you should use GPU but if it is busy then you always can fall back to your CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use indexing of tokens from [vocabulary-embedding](./vocabulary-embedding.ipynb) this does not clip the indexes of the words to `vocab_size`.\n",
    "\n",
    "Use the index of outside words to replace them with several `oov` words (`oov` , `oov0`, `oov1`, ...) that appear in the same description and headline. This will allow headline generator to replace the oov with the same word in the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN0 = 'vocabulary-embedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement the \"simple\" model from http://arxiv.org/pdf/1512.01712v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can start training from a pre-existing model. This allows you to run this notebooks many times, each time using different parameters and passing the end result of one run to be the input of the next.\n",
    "\n",
    "I've started with `maxlend=0` (see below) in which the description was ignored. I then moved to start with a high `LR` and the manually lowering it. I also started with `nflips=0` in which the original headlines is used as-is and slowely moved to `12` in which half the input headline was fliped with the predictions made by the model (the paper used fixed 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN1 = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input data (`X`) is made from `maxlend` description words followed by `eos`\n",
    "followed by headline words followed by `eos`\n",
    "if description is shorter than `maxlend` it will be left padded with `empty`\n",
    "if entire data is longer than `maxlen` it will be clipped and if it is shorter it will be right padded with empty.\n",
    "\n",
    "labels (`Y`) are the headline words followed by `eos` and clipped or padded to `maxlenh`\n",
    "\n",
    "In other words the input is made from a `maxlend` half in which the description is padded from the left\n",
    "and a `maxlenh` half in which `eos` is followed by a headline followed by another `eos` if there is enough space.\n",
    "\n",
    "The labels match only the second half and \n",
    "the first label matches the `eos` at the start of the second half (following the description in the first half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlend=50 # 0 - if we dont want to use description at all\n",
    "maxlenh=50\n",
    "maxlen = maxlend + maxlenh\n",
    "rnn_size = 512 # must be same as 160330-word-gen\n",
    "rnn_layers = 3  # match FN1\n",
    "batch_norm=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the out of the first `activation_rnn_size` nodes from the top LSTM layer will be used for activation and the rest will be used to select predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation_rnn_size = 40 if maxlend else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "seed=42\n",
    "p_W, p_U, p_dense, weight_decay = 0, 0, 0, 0\n",
    "optimizer = 'adam'\n",
    "LR = 1e-4\n",
    "batch_size=64\n",
    "nflips=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = 160\n",
    "nb_val_samples = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/%s.pkl'%FN0, 'rb') as fp:\n",
    "    embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "vocab_size, embedding_size = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36723, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/%s.data.pkl'%FN0, 'rb') as fp:\n",
    "    X, Y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#maxlend = max([len(x) for x in X])\n",
    "#maxlenh = max([len(y) for y in Y])\n",
    "#maxlend, maxlenh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_unknown_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples 281 281\n",
      "dimension of embedding space for words 100\n",
      "vocabulary size 36723 the last 10 words can be used as place holders for unknown/oov words\n",
      "total number of different words 36724 36724\n",
      "number of words outside vocabulary which we can substitue using glove similarity 47\n",
      "number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov) -46\n"
     ]
    }
   ],
   "source": [
    "print ('number of examples',len(X),len(Y))\n",
    "print ('dimension of embedding space for words',embedding_size)\n",
    "print ('vocabulary size', vocab_size, 'the last %d words can be used as place holders for unknown/oov words'%nb_unknown_words)\n",
    "print ('total number of different words',len(idx2word), len(word2idx))\n",
    "print ('number of words outside vocabulary which we can substitue using glove similarity', len(glove_idx2idx))\n",
    "print ('number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov)',len(idx2word)-vocab_size-len(glove_idx2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(nb_unknown_words):\n",
    "    idx2word[vocab_size-1-i] = '<%d>'%i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when printing mark words outside vocabulary with `^` at their end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oov0 = vocab_size-nb_unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(oov0, len(idx2word)):\n",
    "    idx2word[i] = idx2word[i]+'^'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 211, 70, 70)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=nb_val_samples, random_state=seed)\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty = 0\n",
    "eos = 1\n",
    "idx2word[empty] = '_'\n",
    "idx2word[eos] = '~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "import random, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prt(label, x):\n",
    "    print (label+':', end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for w in x:\n",
    "        print (idx2word[w], end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: \n",
      "\n",
      "Lyft to unleash self-driving cars on Bay Area roads \n",
      "\n",
      "D: \n",
      "\n",
      "SAN FRANCISCO — Self-driving Lyfts are coming to the Bay Area, promising to give local residents a first-hand look at the technology that’s poised to dramatically change the nature of transportation. Lyft will launch a pilot fleet of self-driving cars to pick up local passengers, the San Francisco-based ride-hailing company said Thursday, though it didn’t reveal an exact start date. The announcement comes as Lyft is accelerating its efforts to dominate the self-driving car market and compete with the likes of Uber, Google and Tesla — Lyft recently opened a new autonomous vehicle hub in Palo Alto and earlier this summer announced plans to bring self-driving cars to Boston. Now Lyft plans to unleash autonomous vehicles on busy Bay Area roads, where they will have to interact with local drivers, bicyclists and pedestrians, representing a crucial test of the technology. Lyft has teamed up with another startup — Drive.ai — which already has obtained the necessary permits from state regulators to test self-driving cars on public roads. The partnership is a signal that Lyft learned its lesson from the failure of competitor Uber’s self-driving car launch in San Francisco last year. Mountain View-based Drive.ai, born from Stanford University’s Artificial Intelligence Lab, has been testing its self-driving cars on California roads for more than a year. “The majority of the world hasn’t seen autonomous vehicles,” said Drive.ai co-founder and president Carol Reiley. “For them to have a chance to actually ride in an AV car is just so exciting. We really want to start making this a reality and start bringing this to real customers — this isn’t just a demo.” Lyft customers will be able to opt-in to the pilot program, and when they use the Lyft app to summon a ride, they might be matched with an autonomous car free of charge. A safety driver will be behind the wheel, ready to take control if needed, Reiley said. The cars, which will belong to Drive.ai — not Lyft — will be four-door sedans outfitted with Drive.ai’s self-driving sensors and software. Neither Reiley nor Lyft would say where in the Bay Area the cars will be available. Because Drive.ai already has the California permit, Lyft may avoid repeating the fiasco that was Uber’s San Francisco autonomous vehicle launch. Uber rolled out a fleet of self-driving cars in December, but the ride-hailing giant refused to apply for the $150 testing permit. After a contentious, week-long stand-off, the California Department of Motor Vehicles pulled the Uber cars’ registrations and forced them off the road. Uber finally backed down in March and agreed to apply for the permit, which the DMV granted. Now Uber’s cars are back on the streets of San Francisco — but not picking up passengers. The high-profile fight helped cement Uber’s reputation as a bull-headed rule-breaker. Lyft doesn’t plan to apply for a permit either, but by teaming up with a partner that already has one, Lyft is signaling yet again that it’s the “good guy” in the ride-hailing field. Even prior to Thursday’s announcement, Lyft has taken advantage of a recent string of scandals plaguing Uber — including allegations of sexual harassment and other inappropriate behavior at the office, a lawsuit accusing Uber of stealing rival Waymo’s self-driving car technology, and a criminal probe into Uber’s use of a software tool to evade law enforcement stings. Meanwhile, Lyft is touting its feel-good policies — such as a program that lets passengers round-up their fares and donate that money to charity. And Lyft is growing quickly. The smaller ride-hailing company last week announced its platform is live across 40 states. But Uber has a head start in the self-driving car market. Uber has been picking up passengers in autonomous vehicles in Pittsburgh since 2016, and earlier this year launched a similar pilot in Arizona. Lyft has yet to launch its own self-driving fleet, though in June the startup announced plans to bring autonomous cars to Boston via a partnership with nuTonomy. A Lyft spokeswoman on Wednesday said the company remains on track to launch the Boston pilot in the coming months. These pilot programs bring Lyft one step closer to reaching its ultimate goal of a driverless future. In 2016, Lyft President John Zimmer predicted that autonomous vehicles will account for the majority of Lyft rides within five years. And getting real people to test the technology plays a major role in facilitating its wide-spread deployment, said Bryant Walker Smith, a Stanford Law School researcher and self-driving car expert. “It’s a very important step, to invite the public into these vehicles,” he said. “People tend to feel more favorable about automated driving once they’ve experienced these types of demonstrations.” \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 160\n",
    "prt('H',Y_train[i])\n",
    "prt('D',X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: \n",
      "\n",
      "Rust application that converts C++ libraries to single self-contained headers \n",
      "\n",
      "D: \n",
      "\n",
      "This is my first Rust project, mainly created to start getting used to the language. My intention is to improve as I get better with Rust and the final goal is being able to successfully use it on popular libraries. I also do not encourage people to create single-header libraries and use those in their projects: they're mainly useful when dealing with very complicated build systems or when experimenting on an online compiler that doesn't allow users to easily import multiple files. Contributions and code reviews are welcome! Given a set of paths containing the C++ library's header files and a \"top-level include\" file where the graph traversal will start from, outputs a self-contained single-header version of the library to . Here's the auto-generated help: is currently able to transform , my latest C++17 header-only library, to a single-header version. In fact, I've used to add two badges to 's README that allow users to try the library either on wandbox or on godbolt. This idea was taken from Michael Park's excellent variant implementation: . The command used to transform was: Since 0.1.1, supports multiple library include paths and \"absolute directives\". My library, which depends on , can be transformed to a single header as follows: A single-header version of can be created using as follows: I haven't tested it very thorougly, but I compiled the example on 's README without any hiccups. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 50\n",
    "prt('H',Y_test[i])\n",
    "prt('D',X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed weight initialization\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularizer = l2(weight_decay) if weight_decay else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01773875,  0.06372642,  0.03280158, ..., -0.01024496,\n",
       "        -0.06710091, -0.05544016],\n",
       "       [-0.06625115,  0.01928704, -0.02624818, ...,  0.05614735,\n",
       "         0.05473008,  0.03957156],\n",
       "       [-0.0038194 , -0.024487  ,  0.072812  , ..., -0.01459   ,\n",
       "         0.08278   ,  0.027062  ],\n",
       "       ..., \n",
       "       [-0.076047  , -0.060407  ,  0.029848  , ...,  0.024915  ,\n",
       "         0.084378  , -0.01159   ],\n",
       "       [-0.05896605,  0.06575593,  0.04508276, ...,  0.04003331,\n",
       "        -0.01954881, -0.04167179],\n",
       "       [-0.0213262 ,  0.00867258, -0.01099002, ...,  0.03958262,\n",
       "        -0.00101131,  0.01165937]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a standaed stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size,\n",
    "                    input_length=maxlen,\n",
    "                    embeddings_regularizer=regularizer, weights=[embedding], mask_zero=True,\n",
    "                    name='embedding_1'))\n",
    "\n",
    "for i in range(rnn_layers):\n",
    "    lstm = LSTM(rnn_size, return_sequences=True, # batch_norm=batch_norm,\n",
    "                kernel_regularizer=regularizer, recurrent_regularizer=regularizer,\n",
    "                bias_regularizer=regularizer, dropout=p_W, recurrent_dropout=p_U,\n",
    "                name='lstm_%d'%(i+1)\n",
    "                  )\n",
    "    model.add(lstm)\n",
    "    model.add(Dropout(p_dense,name='dropout_%d'%(i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special layer that reduces the input just to its headline part (second half).\n",
    "For each word in this part it concatenate the output of the previous layer (RNN)\n",
    "with a weighted average of the outputs of the description part.\n",
    "In this only the last `rnn_size - activation_rnn_size` are used from each output.\n",
    "The first `activation_rnn_size` output is used to computer the weights for the averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "import keras.backend as K\n",
    "\n",
    "def simple_context(X, mask, n=activation_rnn_size, maxlend=maxlend, maxlenh=maxlenh):\n",
    "    desc, head = X[:,:maxlend,:], X[:,maxlend:,:]\n",
    "    head_activations, head_words = head[:,:,:n], head[:,:,n:]\n",
    "    desc_activations, desc_words = desc[:,:,:n], desc[:,:,n:]\n",
    "    \n",
    "    # RTFM http://deeplearning.net/software/theano/library/tensor/basic.html#theano.tensor.batched_tensordot\n",
    "    # activation for every head word and every desc word\n",
    "    activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2,2))\n",
    "    # make sure we dont use description words that are masked out\n",
    "    activation_energies = activation_energies + -1e20*K.expand_dims(1.-K.cast(mask[:, :maxlend],'float32'),1)\n",
    "    \n",
    "    # for every head word compute weights for every desc word\n",
    "    activation_energies = K.reshape(activation_energies,(-1,maxlend))\n",
    "    activation_weights = K.softmax(activation_energies)\n",
    "    activation_weights = K.reshape(activation_weights,(-1,maxlenh,maxlend))\n",
    "\n",
    "    # for every head word compute weighted average of desc words\n",
    "    desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2,1))\n",
    "    return K.concatenate((desc_avg_word, head_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if activation_rnn_size:\n",
    "    model.add(Lambda(simple_context,\n",
    "                     mask = lambda inputs, mask: mask[:,maxlend:],\n",
    "                     output_shape = lambda input_shape: (input_shape[0], maxlenh, 2*(rnn_size - activation_rnn_size)),\n",
    "                     name='simplecontext_1'))\n",
    "model.add(TimeDistributed(Dense(vocab_size,\n",
    "                                kernel_regularizer=regularizer, bias_regularizer=regularizer,\n",
    "                                name = 'timedistributed_1')))\n",
    "model.add(Activation('softmax', name='activation_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop # usually I prefer Adam but article used rmsprop\n",
    "# opt = Adam(lr=LR)  # keep calm and reduce learning rate\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr,np.float32(LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          3672300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 512)          1255424   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "simplecontext_1 (Lambda)     (None, 50, 944)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 36723)         34703235  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 36723)         0         \n",
      "=================================================================\n",
      "Total params: 43,829,359\n",
      "Trainable params: 43,829,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if FN1:\n",
    "    model.load_weights('data/%s.hdf5'%FN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lpadd(x, maxlend=maxlend, eos=eos):\n",
    "    \"\"\"left (pre) pad a description to maxlend and then add eos.\n",
    "    The eos is the input to predicting the first word in the headline\n",
    "    \"\"\"\n",
    "    assert maxlend >= 0\n",
    "    if maxlend == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlend:\n",
    "        x = x[-maxlend:]\n",
    "        n = maxlend\n",
    "    return [empty]*(maxlend-n) + x + [eos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = [lpadd([3]*26)]\n",
    "# pad from right (post) so the first maxlend will be description followed by headline\n",
    "data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(data[:,maxlend] == eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 100), <map at 0x109a17da0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,map(len, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 36723)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict(data, verbose=0, batch_size=1)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this section is only used to generate examples. you can skip it if you just want to understand how the training works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variation to https://github.com/ryankiros/skip-thoughts/blob/master/decoding/search.py\n",
    "def beamsearch(predict, start=[empty]*maxlend + [eos],\n",
    "               k=1, maxsample=maxlen, use_unk=True, empty=empty, eos=eos, temperature=1.0):\n",
    "    \"\"\"return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
    "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
    "    \"\"\"\n",
    "    def sample(energy, n, temperature=temperature):\n",
    "        \"\"\"sample at most n elements according to their energy\"\"\"\n",
    "        n = min(n,len(energy))\n",
    "        prb = np.exp(-np.array(energy) / temperature )\n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            z = np.sum(prb)\n",
    "            r = np.argmax(np.random.multinomial(1, prb/z, 1))\n",
    "            res.append(r)\n",
    "            prb[r] = 0. # make sure we select each element only once\n",
    "        return res\n",
    "\n",
    "    dead_k = 0 # samples that reached eos\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_k = 1 # samples that did not yet reached eos\n",
    "    live_samples = [list(start)]\n",
    "    live_scores = [0]\n",
    "\n",
    "    while live_k:\n",
    "        # for every possible live sample calc prob for every possible label \n",
    "        probs = predict(live_samples, empty=empty)\n",
    "\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:,None] - np.log(probs)\n",
    "        cand_scores[:,empty] = 1e20\n",
    "        if not use_unk:\n",
    "            for i in range(nb_unknown_words):\n",
    "                cand_scores[:,vocab_size - 1 - i] = 1e20\n",
    "        live_scores = list(cand_scores.flatten())\n",
    "        \n",
    "\n",
    "        # find the best (lowest) scores we have from all possible dead samples and\n",
    "        # all live samples and all possible new words added\n",
    "        scores = dead_scores + live_scores\n",
    "        ranks = sample(scores, k)\n",
    "        n = len(dead_scores)\n",
    "        ranks_dead = [r for r in ranks if r < n]\n",
    "        ranks_live = [r - n for r in ranks if r >= n]\n",
    "        \n",
    "        dead_scores = [dead_scores[r] for r in ranks_dead]\n",
    "        dead_samples = [dead_samples[r] for r in ranks_dead]\n",
    "        \n",
    "        live_scores = [live_scores[r] for r in ranks_live]\n",
    "\n",
    "        # append the new words to their appropriate live sample\n",
    "        voc_size = probs.shape[1]\n",
    "        live_samples = [live_samples[r//voc_size]+[r%voc_size] for r in ranks_live]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        # even if len(live_samples) == maxsample we dont want it dead because we want one\n",
    "        # last prediction out of it to reach a headline of maxlenh\n",
    "        zombie = [s[-1] == eos or len(s) > maxsample for s in live_samples]\n",
    "        \n",
    "        # add zombies to the dead\n",
    "        dead_samples += [s for s,z in zip(live_samples,zombie) if z]\n",
    "        dead_scores += [s for s,z in zip(live_scores,zombie) if z]\n",
    "        dead_k = len(dead_samples)\n",
    "        # remove zombies from the living \n",
    "        live_samples = [s for s,z in zip(live_samples,zombie) if not z]\n",
    "        live_scores = [s for s,z in zip(live_scores,zombie) if not z]\n",
    "        live_k = len(live_samples)\n",
    "\n",
    "    return dead_samples + live_samples, dead_scores + live_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=empty, model=model, maxlen=maxlen):\n",
    "    \"\"\"for every sample, calculate probability for every possible label\n",
    "    you need to supply your RNN model and maxlen - the length of sequences it can handle\n",
    "    \"\"\"\n",
    "    sample_lengths = list(map(len, samples))\n",
    "    assert all(l > maxlend for l in sample_lengths)\n",
    "    assert all(l[maxlend] == eos for l in samples)\n",
    "    # pad from right (post) so the first maxlend will be description followed by headline\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    probs = model.predict(data, verbose=0, batch_size=batch_size)\n",
    "    return np.array([prob[sample_length-maxlend-1] for prob, sample_length in zip(probs, sample_lengths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_fold(xs):\n",
    "    \"\"\"convert list of word indexes that may contain words outside vocab_size to words inside.\n",
    "    If a word is outside, try first to use glove_idx2idx to find a similar word inside.\n",
    "    If none exist then replace all accurancies of the same unknown word with <0>, <1>, ...\n",
    "    \"\"\"\n",
    "    xs = [x if x < oov0 else glove_idx2idx.get(x,x) for x in xs]\n",
    "    # the more popular word is <0> and so on\n",
    "    outside = sorted([x for x in xs if x >= oov0])\n",
    "    # if there are more than nb_unknown_words oov words then put them all in nb_unknown_words-1\n",
    "    outside = dict((x,vocab_size-1-min(i, nb_unknown_words-1)) for i, x in enumerate(outside))\n",
    "    xs = [outside.get(x,x) for x in xs]\n",
    "    return xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_unfold(desc,xs):\n",
    "    # assume desc is the unfolded version of the start of xs\n",
    "    unfold = {}\n",
    "    for i, unfold_idx in enumerate(desc):\n",
    "        fold_idx = xs[i]\n",
    "        if fold_idx >= oov0:\n",
    "            unfold[fold_idx] = unfold_idx\n",
    "    return [unfold.get(x,x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(keras_rnn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import Levenshtein\n",
    "\n",
    "def gensamples(skips=2, k=10, batch_size=batch_size, short=True, temperature=1., use_unk=True):\n",
    "    i = random.randint(0,len(X_test)-1)\n",
    "    print ('HEAD:',' '.join(idx2word[w] for w in Y_test[i][:maxlenh]))\n",
    "    print ('DESC:',' '.join(idx2word[w] for w in X_test[i][:maxlend]))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print ('HEADS:')\n",
    "    x = X_test[i]\n",
    "    samples = []\n",
    "\n",
    "    if maxlend == 0:\n",
    "        skips = [0]\n",
    "    else:\n",
    "        skips = range(min(maxlend,len(x)), max(maxlend,len(x)), abs(maxlend - len(x)) // skips + 1)\n",
    "    for s in skips:\n",
    "        start = lpadd(x[:s])\n",
    "        fold_start = vocab_fold(start)\n",
    "        sample, score = beamsearch(predict=keras_rnn_predict, start=fold_start, k=k, temperature=temperature, use_unk=use_unk)\n",
    "        assert all(s[maxlend] == eos for s in sample)\n",
    "        samples += [(s,start,scr) for s,scr in zip(sample,score)]\n",
    "\n",
    "    samples.sort(key=lambda x: x[-1])\n",
    "    codes = []\n",
    "    for sample, start, score in samples:\n",
    "        code = ''\n",
    "        words = []\n",
    "        sample = vocab_unfold(start, sample)[len(start):]\n",
    "        for w in sample:\n",
    "            if w == eos:\n",
    "                break\n",
    "            words.append(idx2word[w])\n",
    "            code += chr(w//(256*256)) + chr((w//256)%256) + chr(w%256)\n",
    "        if short:\n",
    "            distance = min([100] + [-Levenshtein.jaro(code,c) for c in codes])\n",
    "            if distance > -0.6:\n",
    "                print (score, ' '.join(words))\n",
    "        #         print '%s (%.2f) %f'%(' '.join(words), score, distance)\n",
    "        else:\n",
    "                print (score, ' '.join(words))\n",
    "        codes.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: How a bullet turns into a beep\n",
      "DESC: That last character is U+2022. Select that line with the mouse, right-click, and select Copy to copy it to the clipboard. Now go to a command prompt and paste it and hit Enter. You'd expect a • to be printed, but instead you get a beep. What happened? Hm, there's\n",
      "HEADS:\n",
      "2.25725698471 \n",
      "5.799254179 of\n"
     ]
    }
   ],
   "source": [
    "gensamples(skips=2, batch_size=batch_size, k=10, temperature=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generator generates batches of inputs and outputs/labels for training. The inputs are each made from two parts. The first maxlend words are the original description, followed by `eos` followed by the headline which we want to predict, except for the last word in the headline which is always `eos` and then `empty` padding until `maxlen` words.\n",
    "\n",
    "For each, input, the output is the headline words (without the start `eos` but with the ending `eos`) padded with `empty` words up to `maxlenh` words. The output is also expanded to be y-hot encoding of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more realistic, the second part of the input should be the result of generation and not the original headline.\n",
    "Instead we will flip just `nflips` words to be from the generator, but even this is too hard and instead\n",
    "implement flipping in a naive way (which consumes less time.) Using the full input (description + eos + headline) generate predictions for outputs. For nflips random words from the output, replace the original word with the word with highest probability from the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_headline(x, nflips=None, model=None, debug=False):\n",
    "    \"\"\"given a vectorized input (after `pad_sequences`) flip some of the words in the second half (headline)\n",
    "    with words predicted by the model\n",
    "    \"\"\"\n",
    "    if nflips is None or model is None or nflips <= 0:\n",
    "        return x\n",
    "    \n",
    "    batch_size = len(x)\n",
    "    assert np.all(x[:,maxlend] == eos)\n",
    "    probs = model.predict(x, verbose=0, batch_size=batch_size)\n",
    "    x_out = x.copy()\n",
    "    for b in range(batch_size):\n",
    "        # pick locations we want to flip\n",
    "        # 0...maxlend-1 are descriptions and should be fixed\n",
    "        # maxlend is eos and should be fixed\n",
    "        flips = sorted(random.sample(range(maxlend+1,maxlen), nflips))\n",
    "        if debug and b < debug:\n",
    "            print (b,)\n",
    "        for input_idx in flips:\n",
    "            if x[b,input_idx] == empty or x[b,input_idx] == eos:\n",
    "                continue\n",
    "            # convert from input location to label location\n",
    "            # the output at maxlend (when input is eos) is feed as input at maxlend+1\n",
    "            label_idx = input_idx - (maxlend+1)\n",
    "            prob = probs[b, label_idx]\n",
    "            w = prob.argmax()\n",
    "            if w == empty:  # replace accidental empty with oov\n",
    "                w = oov0\n",
    "            if debug and b < debug:\n",
    "                print ('%s => %s'%(idx2word[x_out[b,input_idx]],idx2word[w]),)\n",
    "            x_out[b,input_idx] = w\n",
    "        if debug and b < debug:\n",
    "            print\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_seq_labels(xds, xhs, nflips=None, model=None, debug=False):\n",
    "    \"\"\"description and hedlines are converted to padded input vectors. headlines are one-hot to label\"\"\"\n",
    "    batch_size = len(xhs)\n",
    "    assert len(xds) == batch_size\n",
    "    x = [vocab_fold(lpadd(xd)+xh) for xd,xh in zip(xds,xhs)]  # the input does not have 2nd eos\n",
    "    x = sequence.pad_sequences(x, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    x = flip_headline(x, nflips=nflips, model=model, debug=debug)\n",
    "    \n",
    "    y = np.zeros((batch_size, maxlenh, vocab_size))\n",
    "    for i, xh in enumerate(xhs):\n",
    "        xh = vocab_fold(xh) + [eos] + [empty]*maxlenh  # output does have a eos at end\n",
    "        xh = xh[:maxlenh]\n",
    "        y[i,:,:] = np_utils.to_categorical(xh, vocab_size)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(Xd, Xh, batch_size=batch_size, nb_batches=None, nflips=None, model=None, debug=False, seed=seed):\n",
    "    \"\"\"yield batches. for training use nb_batches=None\n",
    "    for validation generate deterministic results repeating every nb_batches\n",
    "    \n",
    "    while training it is good idea to flip once in a while the values of the headlines from the\n",
    "    value taken from Xh to value generated by the model.\n",
    "    \"\"\"\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        xds = []\n",
    "        xhs = []\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        new_seed = random.randint(0, sys.maxsize)\n",
    "        random.seed(c+123456789+seed)\n",
    "        for b in range(batch_size):\n",
    "            t = random.randint(0,len(Xd)-1)\n",
    "\n",
    "            xd = Xd[t]\n",
    "            s = random.randint(min(maxlend,len(xd)), max(maxlend,len(xd)))\n",
    "            xds.append(xd[:s])\n",
    "            \n",
    "            xh = Xh[t]\n",
    "            s = random.randint(min(maxlenh,len(xh)), max(maxlenh,len(xh)))\n",
    "            xhs.append(xh[:s])\n",
    "\n",
    "        # undo the seeding before we yield inorder not to affect the caller\n",
    "        c+= 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(xds, xhs, nflips=nflips, model=model, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 100), (64, 50, 36723), 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = next(gen(X_train, Y_train, batch_size=batch_size))\n",
    "r[0].shape, r[1].shape, len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_gen(gen, n=5):\n",
    "    Xtr,Ytr = next(gen)\n",
    "    for i in range(n):\n",
    "        assert Xtr[i,maxlend] == eos\n",
    "        x = Xtr[i,:maxlend]\n",
    "        y = Xtr[i,maxlend:]\n",
    "        yy = Ytr[i,:]\n",
    "        yy = np.where(yy)[1]\n",
    "        prt('L',yy)\n",
    "        prt('H',y)\n",
    "        if maxlend:\n",
    "            prt('D',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: \n",
      "\n",
      "Why people think Germans are so efficient ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Why people think Germans are so efficient _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "Germany’s latest folly to their itinerary. According to Joseph Pearson, however, who explores German idiosyncrasies on his blog The Needle and in his upcoming book Berlin, the delayed airport shouldn’t be critiqued but celebrated precisely because it contradicts the long-held <0>^ a sign of history repetition its course. When things \n",
      "\n",
      "L: \n",
      "\n",
      "On Hiding a Plaintext Length by Preencryption (2011) [pdf] ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ On Hiding a Plaintext Length by Preencryption (2011) [pdf] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "L: \n",
      "\n",
      "Log Book with Computer Bug (Sep 9, 1947) ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Log Book with Computer Bug (Sep 9, 1947) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Enter the terms you wish to search for. \n",
      "\n",
      "L: \n",
      "\n",
      "The joy of veg (2011) ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ The joy of veg (2011) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "shop like that, but if it gets more of us eating more veg then I'm all for it). In any case, there are plenty of quick and cheery meat-free meals – and they don't all have to be based on pasta (though of course, that's a noble ingredient that can \n",
      "\n",
      "L: \n",
      "\n",
      "Getting started with Rust ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Getting started with Rust _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "is also a strongly typed language. In other words, variable are of a certain type. We'll get back to it another time. Finally, on the official site, Rust is described as: In case you have never practiced any \"low-level\" language such as C or C++, those terms are certainly new \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_gen(gen(X_train, Y_train, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test fliping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: \n",
      "\n",
      "Why people think Germans are so efficient ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Why people ~ Germans are so efficient _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "Germany’s latest folly to their itinerary. According to Joseph Pearson, however, who explores German idiosyncrasies on his blog The Needle and in his upcoming book Berlin, the delayed airport shouldn’t be critiqued but celebrated precisely because it contradicts the long-held <0>^ a sign of history repetition its course. When things \n",
      "\n",
      "L: \n",
      "\n",
      "On Hiding a Plaintext Length by Preencryption (2011) [pdf] ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ On Hiding ~ Plaintext Length by Preencryption (2011) [pdf] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "L: \n",
      "\n",
      "Log Book with Computer Bug (Sep 9, 1947) ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Log Book with Computer Bug (Sep 9, ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Enter the terms you wish to search for. \n",
      "\n",
      "L: \n",
      "\n",
      "The joy of veg (2011) ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ The joy of veg (2011) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "shop like that, but if it gets more of us eating more veg then I'm all for it). In any case, there are plenty of quick and cheery meat-free meals – and they don't all have to be based on pasta (though of course, that's a noble ingredient that can \n",
      "\n",
      "L: \n",
      "\n",
      "Getting started with Rust ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Getting started with Rust _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "is also a strongly typed language. In other words, variable are of a certain type. We'll get back to it another time. Finally, on the official site, Rust is described as: In case you have never practiced any \"low-level\" language such as C or C++, those terms are certainly new \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_gen(gen(X_train, Y_train, nflips=6, model=model, debug=False, batch_size=batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valgen = gen(X_test, Y_test,nb_batches=3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that valgen repeats itself after nb_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: \n",
      "\n",
      "Understanding Moscow: The Mysteries of the Russian Mindset ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Understanding Moscow: The Mysteries of the Russian Mindset _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "is not something that Russian politicians tend to consider. The debate about the resettlement of those living in the apartment buildings shows yet again that there is still no feedback loop in the Russian political system. The government doesn't make any serious effort to include the people in its decision-making. \n",
      "\n",
      "L: \n",
      "\n",
      "Unpopular Opinion: Peak Outrage ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Unpopular Opinion: Peak Outrage _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "notified users via e-mail and as you access the app that the new TOS will affect them and that they need to accept them in order to continue using Twitter. Upon inspection, some users got alarmed and outraged by a specific section of the TOS that relates to content ownership, \n",
      "\n",
      "L: \n",
      "\n",
      "How will the growth of AI impact the HR and recruitment sectors? ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ How will the growth of AI impact the HR and recruitment sectors? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "activities whilst AI undertakes candidate screening tasks. By using AI in the candidate search process, any risk of unconscious bias on the recruiter’s behalf is reduced. Instead, AI can ensure that recruiters focus on the candidate’s expertise and skills so the most talented applicants shine through, benefiting both the individual \n",
      "\n",
      "L: \n",
      "\n",
      "Understanding Moscow: The Mysteries of the Russian Mindset ~ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "H: \n",
      "\n",
      "~ Understanding Moscow: The Mysteries of the Russian Mindset _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "D: \n",
      "\n",
      "is not something that Russian politicians tend to consider. The debate about the resettlement of those living in the apartment buildings shows yet again that there is still no feedback loop in the Russian political system. The government doesn't make any serious effort to include the people in its decision-making. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    test_gen(valgen, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traingen = gen(X_train, Y_train, batch_size=batch_size, nflips=nflips, model=model)\n",
    "valgen = gen(X_test, Y_test, nb_batches=nb_val_samples//batch_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 100), (64, 50, 36723), 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = next(traingen)\n",
    "r[0].shape, r[1].shape, len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 693s - loss: 5.9540 - val_loss: 10.8047\n",
      "HEAD: Introducing Pytorch for fast.ai\n",
      "DESC: The next fast.ai courses will be based nearly entirely on a new framework we have developed, built on Pytorch. Pytorch is a different kind of deep learning library (dynamic, rather than static), which has been adopted by many (if not most) of the researchers that we most respect, and in\n",
      "HEADS:\n",
      "2.08736634254 \n",
      "5.70818185806 of\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 695s - loss: 6.1029 - val_loss: 10.8107\n",
      "HEAD: Unpopular Opinion: Peak Outrage\n",
      "DESC: On 2 October 2017 Twitter will have new Terms of Service (TOS) for users outside the United States of America. This, obviously, also affects Twitter users in Afrika. Twitter notified users via e-mail and as you access the app that the new TOS will affect them and that they need\n",
      "HEADS:\n",
      "2.12535810471 \n",
      "5.96489524841 the\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 686s - loss: 6.1748 - val_loss: 10.8206\n",
      "HEAD: Tesla flips a switch to increase the range of some cars in Florida\n",
      "DESC: Tesla has pushed an over-the-air update to some of its vehicles in Florida that lets those cars go just a liiiittle bit further, thus helping their owners get that much further away from the devastation of Hurricane Irma. Wondering how that’s even possible? Up until a few months ago, Tesla\n",
      "HEADS:\n",
      "2.20915031433 \n",
      "10.9046673775 The a\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 749s - loss: 6.2366 - val_loss: 10.8245\n",
      "HEAD: Eisenhower and emoji: How I use Things.app to get focus\n",
      "DESC: You know that anxiety you get when there’s something you need to do and you’re trying to keep it in your head? You write it down on your todo list and problem solved! Lather, rinse repeat over the course of a day and now you’ve got anxiety about all the\n",
      "HEADS:\n",
      "5.99142885208 of\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 692s - loss: 6.1820 - val_loss: 10.8271\n",
      "HEAD: How will the growth of AI impact the HR and recruitment sectors?\n",
      "DESC: Answering the question on many people in the recruitment industry’s lips: will AI mean it’s the end of the line for recruiters? Artificial intelligence (AI) is well and truly on the rise across many sectors and industries. In fact, there’s probably been a point where you’ve asked yourself: “could my\n",
      "HEADS:\n",
      "2.22949314117 \n",
      "7.84330868721 Web\n",
      "8.70590806007 Still\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 4269s - loss: 6.2406 - val_loss: 10.8281\n",
      "HEAD: Science debate: Should we embrace an enhanced future?\n",
      "DESC: To write this article, I drank a beverage containing an effective cognitive enhancer - something that helps me - almost daily - to focus. In my pocket, I carry an extension of my memory, on which I made notes for this very story. Caffeine and smart phones might not strike\n",
      "HEADS:\n",
      "2.19861102104 \n",
      "6.11924123764 for\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 656s - loss: 6.1268 - val_loss: 10.8268\n",
      "HEAD: Essential A11 Phone Teardown\n",
      "DESC: New Yorkers stand up for what they believe in. And we're asking you to stand up for repair. This year, New York could be the first state in the nation to pass the Fair Repair Act, A8192 and S618. We have a chance to guarantee our right to repair electronic\n",
      "HEADS:\n",
      "2.17444825172 \n",
      "6.07692813873 the\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1203s - loss: 6.2105 - val_loss: 10.8261\n",
      "HEAD: Multi-stage builds can help you save gigabytes in Docker images\n",
      "DESC: This is a short article that may help you significantly reduce your docker images size. It is based on my experience optimizing the front-end docker image for OneBar. I have spent less than 20 minutes and shrank our biggest image from 1.52Gb to 117Mb. This is the before the optimization:\n",
      "HEADS:\n",
      "2.14907312393 \n",
      "6.08713650703 the\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 10348s - loss: 6.1352 - val_loss: 10.8262\n",
      "HEAD: Depression could be treated with anti-inflammatory drugs\n",
      "DESC: Dr Alan Carson, Reader in Neuropsychiatry, at the University of Edinburgh, said: “All psychiatric and neurological disorders are based in brain and brain is not static but structurally and functionally responsive to a range of biological, psychological and social issues. “Yet institutionally we use an outmoded code which separates brain\n",
      "HEADS:\n",
      "2.15341973305 \n",
      "6.53559327126 with\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 756s - loss: 6.1668 - val_loss: 10.8266\n",
      "HEAD: Geneticists pan paper that claims to predict a person's face from their DNA\n",
      "DESC: A storm of criticism has rained down a paper by genome-sequencing pioneer Craig Venter that claims to predict people’s physical traits from their DNA. Reviewers and even a co-author of the paper say that it overstates the ability to use a person’s genes to identify the individual, which could raise\n",
      "HEADS:\n",
      "2.18524551392 \n",
      "8.33383011818 What\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 3545s - loss: 6.1561 - val_loss: 10.8287\n",
      "HEAD: Equifax's impact checker site is reporting false outcomes\n",
      "DESC: Those hoping to find out if their Social Security number and other identifying info was stolen, along with a potential 143 million other American’s data won’t find answers from Equifax. In what is an unconscionable move by the credit report company, the checker site, hosted by Equifax product TrustID, seems\n",
      "HEADS:\n",
      "2.22851920128 \n",
      "6.19285440445 to\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1855s - loss: 6.1387 - val_loss: 10.8294\n",
      "HEAD: The History of Silicon Valley: Birth of Computers and the Internet\n",
      "DESC: Before the development of electronic computers, the term “computer” referred to people, not machines. It was a job title, designated to someone who performed mathematical equations and calculations by hand. Typically these “computers” were women that, when grouped together were called a computer pool. These women played a major role\n",
      "HEADS:\n",
      "2.25512671471 \n",
      "6.24357366562 the\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 699s - loss: 6.2267 - val_loss: 10.8294\n",
      "HEAD: Evasi0n – an untethered jailbreak for all iPhone, iPod touch, iPad and iPad mini\n",
      "DESC: \n",
      "HEADS:\n",
      "18.5587048531 rearrange timestamp\n",
      "19.9960668087 Spinnaker food\n",
      "Iteration 13\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 678s - loss: 6.1137 - val_loss: 10.8305\n",
      "HEAD: Where Is the App for Escaping a Hurricane?\n",
      "DESC: As Irma descends on Florida, ride-seekers confront a problem Silicon Valley has neglected to solve. There are apps for massages, dog walkers, and anti-hangover IV drips. There are apps for car rides, shuttle buses, helicopters, and scooter bikes. But there is no app for Adrienne Beauchamp, who is sitting in\n",
      "HEADS:\n",
      "2.20030808449 \n",
      "6.17034482956 for\n",
      "Iteration 14\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 719s - loss: 6.1252 - val_loss: 10.8334\n",
      "HEAD: Shadow of the Colossus Was Unfinished, and Better Because of It\n",
      "DESC: Shadow Of The Colossus was broken, unpolished, and incomplete, and the upcoming remake shouldn’t try to fix that. Technically, Team Ico did complete Shadow Of The Colossus. It shipped in 2005. You could put the disc in a PS2 and experience what would become one of the most iconic adventures\n",
      "HEADS:\n",
      "2.17689561844 \n",
      "6.01737833023 of\n",
      "Iteration 15\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 686s - loss: 6.1304 - val_loss: 10.8376\n",
      "HEAD: Telemarketing of Movie Leads to $32M Punishment in Class Action\n",
      "DESC: More than a quarter century after Congress passed the Telephone Consumer Protection Act with the intention of cracking down on unsolicited telephone solicitations, one movie's promotional campaign has proven quite costly. On Thursday, a Missouri federal judge awarded $32.4 million over calls made for Last Ounce of Courage. Producers of\n",
      "HEADS:\n",
      "2.1729786396 \n",
      "6.15954065323 for\n",
      "Iteration 16\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 678s - loss: 6.0502 - val_loss: 10.8434\n",
      "HEAD: My Time with Google's Cellular Service Was Mostly a Disaster\n",
      "DESC: I glimpsed the future before it collapsed into bullshit. I wanted Project Fi, Google’s new and experimental cellular phone service, to be amazing. The idea sounded so superior to the status quo that it just had to be destined for greatness. But like the Star Wars prequels and most food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADS:\n",
      "2.1949634552 \n",
      "6.03046917915 of\n",
      "Iteration 17\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 720s - loss: 6.0299 - val_loss: 10.8496\n",
      "HEAD: Cost of Push Notifications for Smartphones Using Tor Hidden Services\n",
      "DESC: Some users are experiencing issues with previewing PDFs. We are working on a solution.For more information, see our Resources and Help FAQs\n",
      "HEADS:\n",
      "2.22980284691 \n",
      "6.26112651825 to\n",
      "Iteration 18\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 668s - loss: 6.0953 - val_loss: 10.8544\n",
      "HEAD: Facebook will spend as much as $1B on original TV in the next year\n",
      "DESC: The Wall Street Journal reports that Facebook is going into the next year “willing to spend as much as $1 billion” on original video content, building out the roster of exclusive TV on its revamped video tab Watch. In June, the WSJ reported that Facebook was willing to pay up\n",
      "HEADS:\n",
      "2.25321888924 \n",
      "6.66653728485 a\n",
      "Iteration 19\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 699s - loss: 6.0157 - val_loss: 10.8564\n",
      "HEAD: On the discussion of security vulnerabilities. (1853)\n",
      "DESC: The debate over the open discussion of security vulnerabilities long predates the Internet and computers. The recent reaction of some locksmiths to my master keying research paper heightened my interest in this subject. (January '05 update: See also the reaction to my paper on safe locks.) Here's what one of\n",
      "HEADS:\n",
      "2.2571554184 \n",
      "5.98394393921 of\n",
      "Iteration 20\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 709s - loss: 6.0796 - val_loss: 10.8571\n",
      "HEAD: The Crypto Currency Debate: Future of Money or Speculative Hype?\n",
      "DESC: When it comes to any finance-related questions, I am fair game, and those questions usually span the spectrum, from what I think about Warren Buffett (or why I don't agree with everything he says) to whether tech stocks are in a bubble (a perennial question for worry warts). In the\n",
      "HEADS:\n",
      "6.55640745163 in\n",
      "Iteration 21\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 705s - loss: 6.0481 - val_loss: 10.8590\n",
      "HEAD: How a bullet turns into a beep\n",
      "DESC: That last character is U+2022. Select that line with the mouse, right-click, and select Copy to copy it to the clipboard. Now go to a command prompt and paste it and hit Enter. You'd expect a • to be printed, but instead you get a beep. What happened? Hm, there's\n",
      "HEADS:\n",
      "2.20999288559 \n",
      "6.16585683823 for\n",
      "Iteration 22\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 658s - loss: 6.0798 - val_loss: 10.8597\n",
      "HEAD: On the discussion of security vulnerabilities. (1853)\n",
      "DESC: The debate over the open discussion of security vulnerabilities long predates the Internet and computers. The recent reaction of some locksmiths to my master keying research paper heightened my interest in this subject. (January '05 update: See also the reaction to my paper on safe locks.) Here's what one of\n",
      "HEADS:\n",
      "2.18237161636 \n",
      "6.55214762688 a\n",
      "Iteration 23\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 658s - loss: 6.0889 - val_loss: 10.8613\n",
      "HEAD: Airbnb vows to be first company to defy Trump and keep employing Dreamers\n",
      "DESC: Airbnb has become the first major company to pledge to keep employing undocumented immigrants known as “Dreamers” after their work permits expire, defying the Trump administration in what would potentially be a breach of employment law. The plan, revealed in a statement to the Guardian, distinguishes the company from others\n",
      "HEADS:\n",
      "2.15097165108 \n",
      "5.87993574142 of\n",
      "Iteration 24\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 655s - loss: 6.1162 - val_loss: 10.8641\n",
      "HEAD: Depression could be treated with anti-inflammatory drugs\n",
      "DESC: Dr Alan Carson, Reader in Neuropsychiatry, at the University of Edinburgh, said: “All psychiatric and neurological disorders are based in brain and brain is not static but structurally and functionally responsive to a range of biological, psychological and social issues. “Yet institutionally we use an outmoded code which separates brain\n",
      "HEADS:\n",
      "2.1557841301 \n",
      "6.05036473274 to\n",
      "Iteration 25\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1302s - loss: 6.0969 - val_loss: 10.8680\n",
      "HEAD: Why you should hang onto your ideas\n",
      "DESC: People sometimes ask how I came up with the idea for Writing.AI. A decade ago, I was an exhausted grad student trying to finish a ridiculous amount of writing in far too little time. Facing a blank page, I couldn’t move forward until each sentence was a perfect piece of\n",
      "HEADS:\n",
      "2.16787624359 \n",
      "6.13944745064 The\n",
      "Iteration 26\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 688s - loss: 6.0611 - val_loss: 10.8728\n",
      "HEAD: Geneticists pan paper that claims to predict a person's face from their DNA\n",
      "DESC: A storm of criticism has rained down a paper by genome-sequencing pioneer Craig Venter that claims to predict people’s physical traits from their DNA. Reviewers and even a co-author of the paper say that it overstates the ability to use a person’s genes to identify the individual, which could raise\n",
      "HEADS:\n",
      "2.21056652069 \n",
      "6.10686922073 to\n",
      "Iteration 27\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 680s - loss: 6.0781 - val_loss: 10.8790\n",
      "HEAD: Eight 500 Startup's Making a Major Impact on the Retail Industry – Bizimply\n",
      "DESC: We are very proud at Bizimply to be a part of the 500 Startup community and have really appreciated their continuous support. For readers who don’t already know, 500 Startups is an early-stage venture fund and seed accelerator founded by Dave McClure and Christine Tsai in 2010. For this blog\n",
      "HEADS:\n",
      "2.26175117493 \n",
      "8.05295872688 are\n",
      "Iteration 28\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 691s - loss: 6.1105 - val_loss: 10.8839\n",
      "HEAD: And now the names of Apple’s new iPhones look to have leaked…\n",
      "DESC: We are but days away from the event of the Apple calendar year when the company pulls the curtain up on new iPhone models. And yet the leaks keep coming. The latest juicy tidbit is what looks to be the official names of the three models Apple is rumored to\n",
      "HEADS:\n",
      "2.28071331978 \n",
      "6.29421281815 to\n",
      "Iteration 29\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 714s - loss: 6.0738 - val_loss: 10.8857\n",
      "HEAD: The Incredible Growth of Python\n",
      "DESC: We recently explored how wealthy countries (those defined as high-income by the World Bank) tend to visit a different set of technologies than the rest of the world. Among the largest differences we saw was in the programming language Python. When we focus on high-income countries, the growth of Python\n",
      "HEADS:\n",
      "2.25933742523 \n",
      "6.34151101112 to\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(30):\n",
    "    print ('Iteration', iteration)\n",
    "    h = model.fit_generator(traingen, steps_per_epoch=nb_train_samples//batch_size,\n",
    "                        epochs=1, validation_data=valgen, validation_steps=nb_val_samples\n",
    "                           )\n",
    "    for k,v in h.history.items():\n",
    "        history[k] = history.get(k,[]) + v\n",
    "    with open('data/%s.history.pkl'%FN,'wb') as fp:\n",
    "        pickle.dump(history,fp,-1)\n",
    "    model.save_weights('data/%s.hdf5'%FN, overwrite=True)\n",
    "    gensamples(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHwCAYAAABdWe3bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+rbi8f/cigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111b6f2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "losses = [5.954,6.1029,6.1748,6.2366,6.182,6.2406,6.1268,6.2105,6.1352,6.1668,6.1561,6.1387,6.2267,6.1137,6.1252,6.1304,6.0502,6.0299,6.0953,6.0157,6.0796,6.0481,6.0798,6.0889,6.1162,6.0969,6.0611,6.0781,6.1105,6.0738]\n",
    "val_losses = [10.8047,10.8107,10.8206,10.8245,10.8271,10.8281,10.8268,10.8261,10.8262,10.8266,10.8287,10.8294,10.8294,10.8305,10.8334,10.8376,10.8434,10.8496,10.8544,10.8564,10.8571,10.859,10.8597,10.8613,10.8641,10.868,10.8728,10.879,10.8839,10.8857]\n",
    "\n",
    "plt.figure(figsize=(8, 8))               \n",
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('LSTM Model loss - Embed Dim 100')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(range(30))\n",
    "plt.legend(['train', 'validation'], loc='center')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
